{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18eeb105-3ab7-4f2b-a3e1-9444c515fe1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create EJI Tool Version: Beta (5/14/2021)\n",
    "\n",
    "# This script downloads JSON data from a Census Bureau API for 5-Year ACS Estimates, performs calculations and data formatting in\n",
    "# Pandas dataframes, and uses ESRI (arcpy) tools to join the results to Block Group and Tract geographies. Outputs are created in\n",
    "# file geodatabase and CSV formats. It is intended to automate annual production of NCTCOG's Transit Accessibility Improvement Tool (TAIT).\n",
    "# It is in large part based on a similar tool to streamline production of the annual Environmental Justice Index (EJI).\n",
    "# Key parameters  are specified by the user in the tool interface, but additional parameters can be customized below.\n",
    "\n",
    "#Import some libraries\n",
    "# import arcpy\n",
    "import os\n",
    "import urllib3\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "call = urllib3.PoolManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ad6cce5-e521-4290-ad12-6bb0faf7155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dictionaries describing the data you're requesting from the Census API at the BLOCK GROUP geography.\n",
    "# This has to be split into two queries because 50 variables is the upper limit for requests to this API.\n",
    "# desc_name is a descriptive name of your choosing. This becomes part of the field name. Choose something tidy\n",
    "# that will result in a recognizable field name later.\n",
    "# census_name is the variable name as described here: https://api.census.gov/data/2019/acs/acs5/variables.html\n",
    "\n",
    "bg_desired_col1 =    [{'desc_name': 'Total_Pop', 'census_name': 'B01001_001E'},\n",
    "                      {'desc_name': 'NotHispLatino_WhiteAlone', 'census_name': 'B03002_003E'},\n",
    "                      {'desc_name': 'Hispanic', 'census_name': 'B03002_012E'},\n",
    "                      {'desc_name': 'TotBlk', 'census_name': 'B02001_003E'},\n",
    "                      {'desc_name': 'TotAI', 'census_name': 'B02001_004E'},\n",
    "                      {'desc_name': 'TotAsian', 'census_name': 'B02001_005E'},\n",
    "                      {'desc_name': 'Tot_HPI', 'census_name': 'B02001_006E'},\n",
    "                      {'desc_name': 'TotOther', 'census_name': 'B02001_007E'},\n",
    "                      {'desc_name': 'Tot2Race', 'census_name': 'B02001_008E'},\n",
    "                      {'desc_name': 'TotPSK', 'census_name': 'C17002_001E'},\n",
    "                      {'desc_name': 'BlwPov_Under50', 'census_name': 'C17002_002E'},\n",
    "                      {'desc_name': 'BlwPov_50to99', 'census_name': 'C17002_003E'},\n",
    "                      {'desc_name': 'BlwPov_100to124', 'census_name': 'C17002_004E'},\n",
    "                      {'desc_name': 'PopOver5', 'census_name': 'B16004_001E'},\n",
    "                      {'desc_name': 'SpeakSpanish_5_17', 'census_name': 'B16004_004E'},\n",
    "                      {'desc_name': 'SpeakSpanish_5_17_EnglishVWell', 'census_name': 'B16004_005E'},\n",
    "                      {'desc_name': 'SpeakIE_5_17', 'census_name': 'B16004_009E'},\n",
    "                      {'desc_name': 'SpeakIE_5_17_EnglishVWell', 'census_name': 'B16004_010E'},\n",
    "                      {'desc_name': 'SpeakAsian_5_17', 'census_name': 'B16004_014E'},\n",
    "                      {'desc_name': 'SpeakAsian_5_17_EnglishVWell', 'census_name': 'B16004_015E'},\n",
    "                      {'desc_name': 'SpeakOther_5_17', 'census_name': 'B16004_019E'},\n",
    "                      {'desc_name': 'SpeakOther_5_17_EnglishVWell', 'census_name': 'B16004_020E'},\n",
    "                      {'desc_name': 'SpeakSpanish_18_64', 'census_name': 'B16004_026E'},\n",
    "                      {'desc_name': 'SpeakSpanish_18_64_EnglishVWell', 'census_name': 'B16004_027E'},\n",
    "                      {'desc_name': 'SpeakIE_18_64', 'census_name': 'B16004_031E'},\n",
    "                      {'desc_name': 'SpeakIE_18_64_EnglishVWell', 'census_name': 'B16004_032E'},\n",
    "                      {'desc_name': 'SpeakAsian_18_64', 'census_name': 'B16004_036E'},\n",
    "                      {'desc_name': 'SpeakAsian_18_64_EnglishVWell', 'census_name': 'B16004_037E'},\n",
    "                      {'desc_name': 'SpeakOther_18_64', 'census_name': 'B16004_041E'},\n",
    "                      {'desc_name': 'SpeakOther_18_64_EnglishVWell', 'census_name': 'B16004_042E'},\n",
    "                      {'desc_name': 'SpeakSpanish_65Over', 'census_name': 'B16004_048E'},\n",
    "                      {'desc_name': 'SpeakSpanish_65Over_EnglishVWell', 'census_name': 'B16004_049E'},\n",
    "                      {'desc_name': 'SpeakIE_65Over', 'census_name': 'B16004_053E'},\n",
    "                      {'desc_name': 'SpeakIE_65Over_EnglishVWell', 'census_name': 'B16004_054E'},\n",
    "                      {'desc_name': 'SpeakAsian_65Over', 'census_name': 'B16004_058E'},\n",
    "                      {'desc_name': 'SpeakAsian_65Over_EnglishVWell', 'census_name': 'B16004_059E'},\n",
    "                      {'desc_name': 'SpeakOther_65Over', 'census_name': 'B16004_063E'},\n",
    "                      {'desc_name': 'SpeakOther_65Over_EnglishVWell', 'census_name': 'B16004_064E'},\n",
    "                     ]\n",
    "bg_desired_col2 =    [{'desc_name': 'Age14Under1', 'census_name': 'B01001_003E'},\n",
    "                      {'desc_name': 'Age14Under2', 'census_name': 'B01001_004E'},\n",
    "                      {'desc_name': 'Age14Under3', 'census_name': 'B01001_005E'},\n",
    "                      {'desc_name': 'Age14Under4', 'census_name': 'B01001_027E'},\n",
    "                      {'desc_name': 'Age14Under5', 'census_name': 'B01001_028E'},\n",
    "                      {'desc_name': 'Age14Under6', 'census_name': 'B01001_029E'},\n",
    "                      {'desc_name': 'Pop18Over', 'census_name': 'B21001_001E'},\n",
    "                      {'desc_name': 'TotalVet', 'census_name': 'B21001_002E'},\n",
    "                      {'desc_name': 'Age65Over1', 'census_name': 'B01001_020E'},\n",
    "                      {'desc_name': 'Age65Over2', 'census_name': 'B01001_021E'},\n",
    "                      {'desc_name': 'Age65Over3', 'census_name': 'B01001_022E'},\n",
    "                      {'desc_name': 'Age65Over4', 'census_name': 'B01001_023E'},\n",
    "                      {'desc_name': 'Age65Over5', 'census_name': 'B01001_024E'},\n",
    "                      {'desc_name': 'Age65Over6', 'census_name': 'B01001_025E'},\n",
    "                      {'desc_name': 'Age65Over7', 'census_name': 'B01001_044E'},\n",
    "                      {'desc_name': 'Age65Over8', 'census_name': 'B01001_045E'},\n",
    "                      {'desc_name': 'Age65Over9', 'census_name': 'B01001_046E'},\n",
    "                      {'desc_name': 'Age65Over10', 'census_name': 'B01001_047E'},\n",
    "                      {'desc_name': 'Age65Over11', 'census_name': 'B01001_048E'},\n",
    "                      {'desc_name': 'Age65Over12', 'census_name': 'B01001_049E'},\n",
    "                      {'desc_name': 'TotalHH', 'census_name': 'B11005_001E'},\n",
    "                      {'desc_name': 'FHH_Family', 'census_name': 'B11005_007E'},\n",
    "                      {'desc_name': 'FHH_NonFamily', 'census_name': 'B11005_010E'},\n",
    "                      {'desc_name': 'ZCHH_Owner', 'census_name': 'B25044_003E'},\n",
    "                      {'desc_name': 'ZCHH_Renter', 'census_name': 'B25044_010E'}\n",
    "                     ]\n",
    "\n",
    "# List of dictionaries describing the data you're requesting from the Census API at the TRACT geography.\n",
    "# desc_name is a descriptive name of your choosing. This becomes part of the field name. Choose something tidy\n",
    "# that will result in a recognizable field name later.\n",
    "# census_name is the variable name as described here: https://api.census.gov/data/2019/acs/acs5/variables.html\n",
    "\n",
    "tract_desired_columns = [{'desc_name': 'TotPopTract', 'census_name': 'B18101_001E'},\n",
    "                         {'desc_name': 'MaleDisabUnder5', 'census_name': 'B18101_004E'},\n",
    "                         {'desc_name': 'MaleDisab5to17', 'census_name': 'B18101_007E'},\n",
    "                         {'desc_name': 'MaleDisab18to34', 'census_name': 'B18101_010E'},\n",
    "                         {'desc_name': 'MaleDisab35to64', 'census_name': 'B18101_013E'},\n",
    "                         {'desc_name': 'MaleDisab65to74', 'census_name': 'B18101_016E'},\n",
    "                         {'desc_name': 'MaleDisab75over', 'census_name': 'B18101_019E'},\n",
    "                         {'desc_name': 'FemDisabUnder5', 'census_name': 'B18101_023E'},\n",
    "                         {'desc_name': 'FemDisab5to17', 'census_name': 'B18101_026E'},\n",
    "                         {'desc_name': 'FemDisab18to34', 'census_name': 'B18101_029E'},\n",
    "                         {'desc_name': 'FemDisab35to64', 'census_name': 'B18101_032E'},\n",
    "                         {'desc_name': 'FemDisab65to74', 'census_name': 'B18101_035E'},\n",
    "                         {'desc_name': 'FemDisab75over', 'census_name': 'B18101_038E'}\n",
    "                        ]\n",
    "\n",
    "# List of county FIPS codes the script will request from the API. Also clips the input\n",
    "# block group and tract geographies.\n",
    "state = '17'\n",
    "counties = {\n",
    "    '031':'Cook',\n",
    "    '043':'DuPage',\n",
    "    '089':'Kane',\n",
    "    '093':'Kendall',\n",
    "    '097':'Lake',\n",
    "    '111':'McHenry',\n",
    "    '197':'Will'\n",
    "}\n",
    "year = '2022'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fa3408b-90fd-46b5-8a40-87b222e3bc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating initial empty dataframe for tracts...\n"
     ]
    }
   ],
   "source": [
    "output_folder = ''\n",
    "parent_folder = ''\n",
    "\n",
    "## TRACT API CALL ##\n",
    "\n",
    "# Initializes list of column names to be inserted into URL for TRACT API call.\n",
    "df_init_columns = []\n",
    "census_column_names = ''\n",
    "\n",
    "for x in tract_desired_columns:\n",
    "    df_init_columns.append(f\"{x['desc_name']}\")\n",
    "    census_column_names += x['census_name'] + ','\n",
    "\n",
    "df_init_columns.extend(['State','County','Tract'])\n",
    "census_column_names = census_column_names[:-1]\n",
    "\n",
    "# Establishes empty pandas dataframe to load data from API into.\n",
    "print(\"Creating initial empty dataframe for tracts...\")\n",
    "results_pd_all_tract = pd.DataFrame(columns = df_init_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "957b65d6-d15e-4a17-996a-83a561369128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.census.gov/data/2022/acs/acs5?get=B18101_001E,B18101_004E,B18101_007E,B18101_010E,B18101_013E,B18101_016E,B18101_019E,B18101_023E,B18101_026E,B18101_029E,B18101_032E,B18101_035E,B18101_038E&in=state:17%20county:031&for=tract\n"
     ]
    }
   ],
   "source": [
    "url = f'https://api.census.gov/data/{year}/acs/acs5?get={census_column_names}&in=state:{state}%20county:{county}&for=tract'\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dacdfcaa-56a5-4696-ab9f-4aef6e6fa8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing county 031...\n",
      "Processing county 043...\n",
      "Processing county 089...\n",
      "Processing county 093...\n",
      "Processing county 097...\n",
      "Processing county 111...\n",
      "Processing county 197...\n",
      "Usings Pandas to calculate and reorder fields (Tracts)...\n"
     ]
    }
   ],
   "source": [
    "# Iterates through each county in counties list to connect to the URL, download the results in JSON format, and insert them into the empty data frame.\n",
    "for county in counties:\n",
    "    print(\"Processing county {}...\".format(county))\n",
    "\n",
    "    url = f'https://api.census.gov/data/{year}/acs/acs5?get={census_column_names}&in=state:{state}%20county:{county}&for=tract'\n",
    "\n",
    "    # print(\"Requesting URL...\")\n",
    "    apicall = call.request('GET', url)\n",
    "\n",
    "    # print(\"Loading results text...\")\n",
    "    results = apicall.data\n",
    "\n",
    "    # print(\"Parsing into json...\")\n",
    "    results_json = json.loads(results)[1:]\n",
    "\n",
    "    # print(\"Loading JSON into Pandas dataframe...\")\n",
    "    results_pd = pd.DataFrame(columns = df_init_columns, data = results_json)\n",
    "\n",
    "    results_pd_all_tract = pd.concat([results_pd_all_tract, results_pd])\n",
    "\n",
    "#Establish a new column in the dataframe with a concatenated GEOID from State, County, and Tract FIPS codes.\n",
    "# print(\"Calculating tract geoid for all counties...\")\n",
    "cols = ['State', 'County', 'Tract']\n",
    "for c in cols:\n",
    "    results_pd_all_tract[c] = results_pd_all_tract[c].astype(str)\n",
    "results_pd_all_tract['Tract_GEOID'] = results_pd_all_tract['State'] + results_pd_all_tract['County'] + results_pd_all_tract['Tract']\n",
    "\n",
    "## TRACT CALCULATIONS AND REFORMATTING ##\n",
    "\n",
    "print('Usings Pandas to calculate and reorder fields (Tracts)...')\n",
    "\n",
    "for col in list(results_pd_all_tract.columns):\n",
    "    if col not in ['Tract_GEOID','County']:\n",
    "        results_pd_all_tract.loc[~results_pd_all_tract[col].apply(lambda x: str(x).isnumeric()), col] = 0\n",
    "        results_pd_all_tract[col] = results_pd_all_tract[col].astype('int64')\n",
    "\n",
    "results_pd_all_tract['WholeTract_PWD'] = 0\n",
    "for gender in ['Male','Fem']:\n",
    "    for age in ['Under5','5to17','18to34','35to64','65to74','75over']:\n",
    "        results_pd_all_tract['WholeTract_PWD'] = results_pd_all_tract['WholeTract_PWD'] + results_pd_all_tract[f'{gender}Disab{age}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7b9d9d6-0122-4dd8-8e8a-510efeb52de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating initial empty dataframe for block groups...\n",
      "Processing county 031...\n",
      "Processing county 043...\n",
      "Processing county 089...\n",
      "Processing county 093...\n",
      "Processing county 097...\n",
      "Processing county 111...\n",
      "Processing county 197...\n",
      "Creating initial empty dataframe for block groups...\n",
      "Processing county 031...\n",
      "Processing county 043...\n",
      "Processing county 089...\n",
      "Processing county 093...\n",
      "Processing county 097...\n",
      "Processing county 111...\n",
      "Processing county 197...\n"
     ]
    }
   ],
   "source": [
    "## BLOCK GROUP API CALL 1 ##\n",
    "   \n",
    "# Initializes list of column names to be inserted into URL for BLOCK GROUP API call.\n",
    "df_init_columns = []\n",
    "census_column_names = ''\n",
    "\n",
    "for x in bg_desired_col1:\n",
    "    df_init_columns.append(f\"{x['desc_name']}\")\n",
    "    census_column_names = census_column_names + x['census_name'] + ','\n",
    "\n",
    "df_init_columns.extend(['State','County','Tract','BG'])\n",
    "census_column_names = census_column_names[:-1]\n",
    "\n",
    "# Establishes empty pandas dataframe to load data from BLOCK GROUP API call into.\n",
    "print(\"Creating initial empty dataframe for block groups...\")\n",
    "results_pd_all_bg1 = pd.DataFrame(columns = df_init_columns)\n",
    "\n",
    "# Iterates through each county in counties list to connect to the URL, download the results in JSON format, and insert them into the empty data frame.\n",
    "for county in counties:\n",
    "    print(f\"Processing county {county}...\")\n",
    "\n",
    "    url = f'https://api.census.gov/data/{year}/acs/acs5?get={census_column_names}&in=state:{state}%20county:{county}&for=block%20group'\n",
    "\n",
    "    # print(\"Requesting URL...\")    \n",
    "    apicall = call.request('GET', url)\n",
    "\n",
    "    # print(\"Loading results text...\")\n",
    "    results = apicall.data\n",
    "\n",
    "    # print(\"Parsing into json...\")\n",
    "    results_json = json.loads(results)[1:]\n",
    "\n",
    "    # print(\"Loading JSON into Pandas dataframe...\")\n",
    "    results_pd = pd.DataFrame(columns = df_init_columns, data = results_json)\n",
    "\n",
    "    results_pd_all_bg1 = pd.concat([results_pd_all_bg1, results_pd])\n",
    "\n",
    "#Establish a new column in the dataframe with a concatenated GEOID from State, County, Tract, and BG FIPS codes.\n",
    "# print(\"Calculating tract geoid for all counties...\")\n",
    "results_pd_all_bg1['GEOID'] = results_pd_all_bg1['State'] + results_pd_all_bg1['County'] + results_pd_all_bg1['Tract'] + results_pd_all_bg1['BG']\n",
    "\n",
    "## BLOCK GROUP API CALL 2 ##\n",
    "   \n",
    "# Initializes list of column names to be inserted into URL for BLOCK GROUP API call.\n",
    "df_init_columns = []\n",
    "census_column_names = ''\n",
    "\n",
    "for x in bg_desired_col2:\n",
    "    df_init_columns.append(f\"{x['desc_name']}\")\n",
    "    census_column_names = census_column_names + x['census_name'] + ','\n",
    "\n",
    "df_init_columns.extend(['State','County','Tract','BG'])\n",
    "census_column_names = census_column_names[:-1]\n",
    "\n",
    "# Establishes empty pandas dataframe to load data from BLOCK GROUP API call into.\n",
    "print(\"Creating initial empty dataframe for block groups...\")\n",
    "results_pd_all_bg2 = pd.DataFrame(columns = df_init_columns)\n",
    "\n",
    "# Iterates through each county in counties list to connect to the URL, download the results in JSON format, and insert them into the empty data frame.\n",
    "for county in counties:\n",
    "    print(f\"Processing county {county}...\")\n",
    "\n",
    "    url = f'https://api.census.gov/data/{year}/acs/acs5?get={census_column_names}&in=state:{state}%20county:{county}&for=block%20group'\n",
    "\n",
    "    # print(\"Requesting URL...\")\n",
    "    apicall = call.request('GET', url)\n",
    "\n",
    "    # print(\"Loading results text...\")\n",
    "    results = apicall.data\n",
    "\n",
    "    # print(\"Parsing into json...\")\n",
    "    results_json = json.loads(results)[1:]\n",
    "\n",
    "    # print(\"Loading JSON into Pandas dataframe...\")\n",
    "    results_pd = pd.DataFrame(columns = df_init_columns, data = results_json)\n",
    "\n",
    "    results_pd_all_bg2 = pd.concat([results_pd_all_bg2, results_pd])\n",
    "\n",
    "#Establish a new column in the dataframe with a concatenated GEOID from State, County, Tract, and BG FIPS codes.\n",
    "# print(\"Calculating tract geoid for all counties...\")\n",
    "results_pd_all_bg2['GEOID'] = results_pd_all_bg2['State'] + results_pd_all_bg2['County'] + results_pd_all_bg2['Tract'] + results_pd_all_bg2['BG']\n",
    "results_pd_all_bg2['Tract_GEOID'] = results_pd_all_bg2['State'] + results_pd_all_bg2['County'] + results_pd_all_bg2['Tract']\n",
    "\n",
    "\n",
    "#Join the two BG-level data frames together.\n",
    "results_pd_notract_bg = pd.merge(results_pd_all_bg1,results_pd_all_bg2,on='GEOID')\n",
    "\n",
    "#Join tract-level PWD data to block groups.\n",
    "results_pd_all_bg = pd.merge(results_pd_notract_bg,results_pd_all_tract,on='Tract_GEOID',how='left',suffixes=('_x','_y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6dedd8cf-07c6-4370-9c2e-56866ad51d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usings Pandas to calculate and reorder fields (Block Groups)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:31: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg['NoCar'] = results_pd_all_bg['ZCHH_Owner'] + results_pd_all_bg['ZCHH_Renter']\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg['Sum_PWD'] = results_pd_all_bg['WholeTract_PWD'].astype('float64') * (results_pd_all_bg['Total_Pop'].astype('float64') / results_pd_all_bg['TotPopTract'].astype('float64'))\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
      "/data/user/0/ru.iiec.pydroid3/cache/ipykernel_10265/506805413.py:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  results_pd_all_bg['CountyText'] = 'temp'\n"
     ]
    }
   ],
   "source": [
    "## BLOCK GROUP CALCULATIONS AND REFORMATTING ##\n",
    "\n",
    "print('Usings Pandas to calculate and reorder fields (Block Groups)...')\n",
    "\n",
    "for col in list(results_pd_all_bg.columns):\n",
    "    if col not in ['GEOID','County_x']:\n",
    "        results_pd_all_bg.loc[~results_pd_all_bg[col].apply(lambda x: str(x).isnumeric()), col] = 0\n",
    "        results_pd_all_bg[col] = results_pd_all_bg[col].astype('int64')\n",
    "\n",
    "results_pd_all_bg['TotalMin'] = results_pd_all_bg['Total_Pop'] - results_pd_all_bg ['NotHispLatino_WhiteAlone']\n",
    "\n",
    "results_pd_all_bg['BlwPov'] = results_pd_all_bg['BlwPov_Under50'] + results_pd_all_bg['BlwPov_50to99'] + results_pd_all_bg['BlwPov_100to124']\n",
    "\n",
    "results_pd_all_bg['TotalLEP'] = 0\n",
    "for language in ['Spanish','IE','Asian','Other']:\n",
    "    results_pd_all_bg['{}LEP'.format(language)] = 0\n",
    "    for age in ['5_17','18_64','65Over']:\n",
    "        results_pd_all_bg['{}LEP'.format(language)] += (results_pd_all_bg['Speak{}_{}'.format(language,age)] - results_pd_all_bg['Speak{}_{}_EnglishVWell'.format(language,age)])\n",
    "    results_pd_all_bg['TotalLEP'] += results_pd_all_bg['{}LEP'.format(language)]\n",
    "\n",
    "results_pd_all_bg['Age65Over'] = 0\n",
    "for i in range(1,12+1):\n",
    "    results_pd_all_bg['Age65Over'] += results_pd_all_bg['Age65Over{}'.format(str(i))]\n",
    "\n",
    "results_pd_all_bg['Age14Under'] = 0\n",
    "for i in range(1,6+1):\n",
    "    results_pd_all_bg['Age14Under'] += results_pd_all_bg['Age14Under{}'.format(str(i))]\n",
    "\n",
    "results_pd_all_bg['TotalFHH'] = results_pd_all_bg['FHH_Family'] + results_pd_all_bg['FHH_NonFamily']\n",
    "\n",
    "results_pd_all_bg['NoCar'] = results_pd_all_bg['ZCHH_Owner'] + results_pd_all_bg['ZCHH_Renter']\n",
    "\n",
    "results_pd_all_bg['Sum_PWD'] = results_pd_all_bg['WholeTract_PWD'].astype('float64') * (results_pd_all_bg['Total_Pop'].astype('float64') / results_pd_all_bg['TotPopTract'].astype('float64'))\n",
    "\n",
    "\n",
    "calculation_fields = [{'variable': 'TotalMin', 'universe': 'Total_Pop', 'pct': 'Pct_TotMin', 'ratio': 'Rat_TotMin'},\n",
    "                      {'variable': 'Hispanic', 'universe': 'Total_Pop', 'pct': 'Pct_Hisp', 'ratio': 'Rat_Hisp'},\n",
    "                      {'variable': 'TotBlk', 'universe': 'Total_Pop', 'pct': 'Pct_TotBlk', 'ratio': 'Rat_TotBlk'},\n",
    "                      {'variable': 'TotAI', 'universe': 'Total_Pop', 'pct': 'Pct_TotAI', 'ratio': 'Rat_TotAI'},\n",
    "                      {'variable': 'TotAsian', 'universe': 'Total_Pop', 'pct': 'Pct_TotAsn', 'ratio': 'Rat_TotAsn'},\n",
    "                      {'variable': 'Tot_HPI', 'universe': 'Total_Pop', 'pct': 'Pct_TotHPI', 'ratio': 'Rat_TotHPI'},\n",
    "                      {'variable': 'TotOther', 'universe': 'Total_Pop', 'pct': 'Pct_TotOth', 'ratio': 'Rat_TotOth'},\n",
    "                      {'variable': 'Tot2Race', 'universe': 'Total_Pop', 'pct': 'Pct_Tot2Ra', 'ratio': 'Rat_Tot2Ra'},\n",
    "                      {'variable': 'BlwPov', 'universe': 'TotPSK', 'pct': 'Pct_BlwPov', 'ratio': 'Rat_BlwPov'},\n",
    "                      {'variable': 'TotalLEP', 'universe': 'PopOver5', 'pct': 'Pct_TotLEP', 'ratio': 'Rat_TotLEP'},\n",
    "                      {'variable': 'SpanishLEP', 'universe': 'PopOver5', 'pct': 'Pct_SpLEP', 'ratio': 'Rat_SpLEP'},\n",
    "                      {'variable': 'IELEP', 'universe': 'PopOver5', 'pct': 'Pct_IE_LEP', 'ratio': 'Rat_IE_LEP'},\n",
    "                      {'variable': 'AsianLEP', 'universe': 'PopOver5', 'pct': 'Pct_AsnLEP', 'ratio': 'Rat_AsnLEP'},\n",
    "                      {'variable': 'OtherLEP', 'universe': 'PopOver5', 'pct': 'Pct_OthLEP', 'ratio': 'Rat_OthLEP'},\n",
    "                      {'variable': 'Age65Over', 'universe': 'Total_Pop', 'pct': 'Pct65_Over', 'ratio': 'Rat_65Over'},\n",
    "                      {'variable': 'TotalFHH', 'universe': 'TotalHH', 'pct': 'Pct_TotFHH', 'ratio': 'Rat_TotFHH'},\n",
    "                      {'variable': 'NoCar', 'universe': 'TotalHH', 'pct': 'Pct_NoCar', 'ratio': 'Rat_NoCar'},\n",
    "                      {'variable': 'Age14Under', 'universe': 'Total_Pop', 'pct': 'Pct14_Unde', 'ratio': 'Rat_14Unde'},\n",
    "                      {'variable': 'TotalVet', 'universe': 'Pop18Over', 'pct': 'Pct_Vet', 'ratio': 'Rat_Vet'},\n",
    "                      {'variable': 'Sum_PWD', 'universe': 'Total_Pop', 'pct': 'Pct_PWD', 'ratio':'Rat_PWD'}\n",
    "                     ]                      \n",
    "\n",
    "for field in calculation_fields:\n",
    "    results_pd_all_bg[field['pct']] = (results_pd_all_bg[field['variable']] / results_pd_all_bg[field['universe']])\n",
    "#    regional_pct = ((np.asarray(results_pd_all_bg.iloc[:,results_pd_all_bg.columns.get_loc(field['variable'])], dtype=np.float64).sum()) / (np.asarray(results_pd_all_bg.iloc[:,results_pd_all_bg.columns.get_loc(field['universe'])], dtype=np.float64).sum()))\n",
    "    regional_pct = float(results_pd_all_bg[field['variable']].sum()) / float(results_pd_all_bg[field['universe']].sum())\n",
    "    results_pd_all_bg[field['ratio']] = results_pd_all_bg[field['pct']] / regional_pct\n",
    "\n",
    "# results_pd_all_bg.loc[results_pd_all_bg['Rat_65Over'] >= 1.0, 'ARP_65Over'] = 'Y'\n",
    "# results_pd_all_bg.loc[results_pd_all_bg['Rat_65Over'] < 1.0, 'ARP_65Over'] = 'N'\n",
    "\n",
    "# results_pd_all_bg.loc[results_pd_all_bg['Rat_BlwPov'] >= 1.0, 'ARP_BlwPov'] = 'Y'\n",
    "# results_pd_all_bg.loc[results_pd_all_bg['Rat_BlwPov'] < 1.0, 'ARP_BlwPov'] = 'N'\n",
    "\n",
    "# results_pd_all_bg.loc[results_pd_all_bg['Rat_PWD'] >= 1.0, 'ARP_PWD'] = 'Y'\n",
    "# results_pd_all_bg.loc[results_pd_all_bg['Rat_PWD'] < 1.0, 'ARP_PWD'] = 'N'\n",
    "\n",
    "results_pd_all_bg['CountyText'] = 'temp'\n",
    "for county in counties:\n",
    "    results_pd_all_bg.loc[results_pd_all_bg['County_x'].astype(str) == county, 'CountyText'] = counties[county]\n",
    "\n",
    "#results_bg_reordered = results_pd_all_bg[['GEOID','CountyText','Total_Pop','TotalMin','Pct_TotMin','Rat_TotMin','Hispanic','Pct_Hisp','Rat_Hisp','TotBlk','Pct_TotBlk','Rat_TotBlk','TotAI','Pct_TotAI','Rat_TotAI','TotAsian','Pct_TotAsn','Rat_TotAsn','Tot_HPI','Pct_TotHPI','Rat_TotHPI','TotOther','Pct_TotOth','Rat_TotOth','Tot2Race','Pct_Tot2Ra','Rat_Tot2Ra','TotPSK','BlwPov','Pct_BlwPov','Rat_BlwPov','PopOver5','TotalLEP','Pct_TotLEP','Rat_TotLEP','SpanishLEP','Pct_SpLEP','Rat_SpLEP','IELEP','Pct_IE_LEP','Rat_IE_LEP','AsianLEP','Pct_AsnLEP','Rat_AsnLEP','OtherLEP','Pct_OthLEP','Rat_OthLEP','Age65Over','Pct65_Over','Rat_65Over','TotalHH','TotalFHH','Pct_TotFHH','Rat_TotFHH','NoCar','Pct_NoCar','Rat_NoCar','Min_RegPct','Pov_RegPct','Both_RegPct']]\n",
    "results_bg_reordered = results_pd_all_bg[['GEOID','Tract_GEOID','CountyText','Total_Pop','TotalMin','Pct_TotMin','Hispanic','Pct_Hisp','TotBlk','Pct_TotBlk','TotAI','Pct_TotAI','TotAsian','Pct_TotAsn','Tot_HPI','Pct_TotHPI','TotOther','Pct_TotOth','Tot2Race','Pct_Tot2Ra','TotPSK','BlwPov','Pct_BlwPov','Rat_BlwPov','PopOver5','TotalLEP','Pct_TotLEP','SpanishLEP','Pct_SpLEP','IELEP','Pct_IE_LEP','AsianLEP','Pct_AsnLEP','OtherLEP','Pct_OthLEP','Age65Over','Pct65_Over','Rat_65Over','TotalHH','NoCar','Pct_NoCar','Rat_NoCar','Age14Under','Pct14_Unde','Rat_14Unde','Pop18Over','TotalVet','Pct_Vet','Rat_Vet','TotPopTract','Sum_PWD','Pct_PWD','Rat_PWD']]\n",
    "\n",
    "results_bg_reordered = results_bg_reordered.rename(columns={'CountyText':'County'})\n",
    "results_bg_reordered = results_bg_reordered.rename(columns={'Tract_GEOID':'TractID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1d54224-ae19-4f88-8952-a4090397a9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOID</th>\n",
       "      <th>TractID</th>\n",
       "      <th>County</th>\n",
       "      <th>Total_Pop</th>\n",
       "      <th>TotalMin</th>\n",
       "      <th>Pct_TotMin</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>Pct_Hisp</th>\n",
       "      <th>TotBlk</th>\n",
       "      <th>Pct_TotBlk</th>\n",
       "      <th>...</th>\n",
       "      <th>Pct14_Unde</th>\n",
       "      <th>Rat_14Unde</th>\n",
       "      <th>Pop18Over</th>\n",
       "      <th>TotalVet</th>\n",
       "      <th>Pct_Vet</th>\n",
       "      <th>Rat_Vet</th>\n",
       "      <th>TotPopTract</th>\n",
       "      <th>Sum_PWD</th>\n",
       "      <th>Pct_PWD</th>\n",
       "      <th>Rat_PWD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>170978601031</td>\n",
       "      <td>17097860103</td>\n",
       "      <td>Lake</td>\n",
       "      <td>696</td>\n",
       "      <td>150</td>\n",
       "      <td>0.215517</td>\n",
       "      <td>43</td>\n",
       "      <td>0.061782</td>\n",
       "      <td>56</td>\n",
       "      <td>0.080460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012931</td>\n",
       "      <td>0.070834</td>\n",
       "      <td>668</td>\n",
       "      <td>40</td>\n",
       "      <td>0.059880</td>\n",
       "      <td>1.505310</td>\n",
       "      <td>3677</td>\n",
       "      <td>79.121023</td>\n",
       "      <td>0.113680</td>\n",
       "      <td>1.123285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>170978601032</td>\n",
       "      <td>17097860103</td>\n",
       "      <td>Lake</td>\n",
       "      <td>848</td>\n",
       "      <td>208</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>163</td>\n",
       "      <td>0.192217</td>\n",
       "      <td>9</td>\n",
       "      <td>0.010613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143868</td>\n",
       "      <td>0.788087</td>\n",
       "      <td>703</td>\n",
       "      <td>32</td>\n",
       "      <td>0.045519</td>\n",
       "      <td>1.144293</td>\n",
       "      <td>3677</td>\n",
       "      <td>96.400326</td>\n",
       "      <td>0.113680</td>\n",
       "      <td>1.123285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>170978601033</td>\n",
       "      <td>17097860103</td>\n",
       "      <td>Lake</td>\n",
       "      <td>2148</td>\n",
       "      <td>461</td>\n",
       "      <td>0.214618</td>\n",
       "      <td>344</td>\n",
       "      <td>0.160149</td>\n",
       "      <td>83</td>\n",
       "      <td>0.038641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117318</td>\n",
       "      <td>0.642653</td>\n",
       "      <td>1803</td>\n",
       "      <td>237</td>\n",
       "      <td>0.131448</td>\n",
       "      <td>3.304418</td>\n",
       "      <td>3677</td>\n",
       "      <td>244.183846</td>\n",
       "      <td>0.113680</td>\n",
       "      <td>1.123285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>170978601041</td>\n",
       "      <td>17097860104</td>\n",
       "      <td>Lake</td>\n",
       "      <td>1906</td>\n",
       "      <td>251</td>\n",
       "      <td>0.131689</td>\n",
       "      <td>211</td>\n",
       "      <td>0.110703</td>\n",
       "      <td>8</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183106</td>\n",
       "      <td>1.003027</td>\n",
       "      <td>1510</td>\n",
       "      <td>128</td>\n",
       "      <td>0.084768</td>\n",
       "      <td>2.130961</td>\n",
       "      <td>2940</td>\n",
       "      <td>311.831973</td>\n",
       "      <td>0.163605</td>\n",
       "      <td>1.616610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017</th>\n",
       "      <td>170978601042</td>\n",
       "      <td>17097860104</td>\n",
       "      <td>Lake</td>\n",
       "      <td>1048</td>\n",
       "      <td>111</td>\n",
       "      <td>0.105916</td>\n",
       "      <td>22</td>\n",
       "      <td>0.020992</td>\n",
       "      <td>14</td>\n",
       "      <td>0.013359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088740</td>\n",
       "      <td>0.486107</td>\n",
       "      <td>955</td>\n",
       "      <td>168</td>\n",
       "      <td>0.175916</td>\n",
       "      <td>4.422301</td>\n",
       "      <td>2940</td>\n",
       "      <td>171.458503</td>\n",
       "      <td>0.163605</td>\n",
       "      <td>1.616610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5433</th>\n",
       "      <td>170978661002</td>\n",
       "      <td>17097866100</td>\n",
       "      <td>Lake</td>\n",
       "      <td>1776</td>\n",
       "      <td>1703</td>\n",
       "      <td>0.958896</td>\n",
       "      <td>1492</td>\n",
       "      <td>0.840090</td>\n",
       "      <td>299</td>\n",
       "      <td>0.168356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293356</td>\n",
       "      <td>1.606959</td>\n",
       "      <td>1147</td>\n",
       "      <td>59</td>\n",
       "      <td>0.051439</td>\n",
       "      <td>1.293097</td>\n",
       "      <td>3570</td>\n",
       "      <td>160.188235</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.891241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5434</th>\n",
       "      <td>170978662001</td>\n",
       "      <td>17097866200</td>\n",
       "      <td>Lake</td>\n",
       "      <td>2725</td>\n",
       "      <td>279</td>\n",
       "      <td>0.102385</td>\n",
       "      <td>25</td>\n",
       "      <td>0.009174</td>\n",
       "      <td>33</td>\n",
       "      <td>0.012110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100917</td>\n",
       "      <td>0.552811</td>\n",
       "      <td>2286</td>\n",
       "      <td>137</td>\n",
       "      <td>0.059930</td>\n",
       "      <td>1.506561</td>\n",
       "      <td>6113</td>\n",
       "      <td>356.617046</td>\n",
       "      <td>0.130869</td>\n",
       "      <td>1.293133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5435</th>\n",
       "      <td>170978662002</td>\n",
       "      <td>17097866200</td>\n",
       "      <td>Lake</td>\n",
       "      <td>1868</td>\n",
       "      <td>339</td>\n",
       "      <td>0.181478</td>\n",
       "      <td>81</td>\n",
       "      <td>0.043362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145075</td>\n",
       "      <td>0.794699</td>\n",
       "      <td>1597</td>\n",
       "      <td>52</td>\n",
       "      <td>0.032561</td>\n",
       "      <td>0.818542</td>\n",
       "      <td>6113</td>\n",
       "      <td>244.462621</td>\n",
       "      <td>0.130869</td>\n",
       "      <td>1.293133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5436</th>\n",
       "      <td>170978662003</td>\n",
       "      <td>17097866200</td>\n",
       "      <td>Lake</td>\n",
       "      <td>1663</td>\n",
       "      <td>245</td>\n",
       "      <td>0.147324</td>\n",
       "      <td>75</td>\n",
       "      <td>0.045099</td>\n",
       "      <td>52</td>\n",
       "      <td>0.031269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131088</td>\n",
       "      <td>0.718083</td>\n",
       "      <td>1389</td>\n",
       "      <td>93</td>\n",
       "      <td>0.066955</td>\n",
       "      <td>1.683151</td>\n",
       "      <td>6113</td>\n",
       "      <td>217.634549</td>\n",
       "      <td>0.130869</td>\n",
       "      <td>1.293133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5437</th>\n",
       "      <td>170979900000</td>\n",
       "      <td>17097990000</td>\n",
       "      <td>Lake</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows  53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             GEOID      TractID County  Total_Pop  TotalMin  Pct_TotMin  \\\n",
       "5013  170978601031  17097860103   Lake        696       150    0.215517   \n",
       "5014  170978601032  17097860103   Lake        848       208    0.245283   \n",
       "5015  170978601033  17097860103   Lake       2148       461    0.214618   \n",
       "5016  170978601041  17097860104   Lake       1906       251    0.131689   \n",
       "5017  170978601042  17097860104   Lake       1048       111    0.105916   \n",
       "...            ...          ...    ...        ...       ...         ...   \n",
       "5433  170978661002  17097866100   Lake       1776      1703    0.958896   \n",
       "5434  170978662001  17097866200   Lake       2725       279    0.102385   \n",
       "5435  170978662002  17097866200   Lake       1868       339    0.181478   \n",
       "5436  170978662003  17097866200   Lake       1663       245    0.147324   \n",
       "5437  170979900000  17097990000   Lake          0         0         NaN   \n",
       "\n",
       "      Hispanic  Pct_Hisp  TotBlk  Pct_TotBlk  ...  Pct14_Unde  Rat_14Unde  \\\n",
       "5013        43  0.061782      56    0.080460  ...    0.012931    0.070834   \n",
       "5014       163  0.192217       9    0.010613  ...    0.143868    0.788087   \n",
       "5015       344  0.160149      83    0.038641  ...    0.117318    0.642653   \n",
       "5016       211  0.110703       8    0.004197  ...    0.183106    1.003027   \n",
       "5017        22  0.020992      14    0.013359  ...    0.088740    0.486107   \n",
       "...        ...       ...     ...         ...  ...         ...         ...   \n",
       "5433      1492  0.840090     299    0.168356  ...    0.293356    1.606959   \n",
       "5434        25  0.009174      33    0.012110  ...    0.100917    0.552811   \n",
       "5435        81  0.043362       0    0.000000  ...    0.145075    0.794699   \n",
       "5436        75  0.045099      52    0.031269  ...    0.131088    0.718083   \n",
       "5437         0       NaN       0         NaN  ...         NaN         NaN   \n",
       "\n",
       "      Pop18Over  TotalVet   Pct_Vet   Rat_Vet  TotPopTract     Sum_PWD  \\\n",
       "5013        668        40  0.059880  1.505310         3677   79.121023   \n",
       "5014        703        32  0.045519  1.144293         3677   96.400326   \n",
       "5015       1803       237  0.131448  3.304418         3677  244.183846   \n",
       "5016       1510       128  0.084768  2.130961         2940  311.831973   \n",
       "5017        955       168  0.175916  4.422301         2940  171.458503   \n",
       "...         ...       ...       ...       ...          ...         ...   \n",
       "5433       1147        59  0.051439  1.293097         3570  160.188235   \n",
       "5434       2286       137  0.059930  1.506561         6113  356.617046   \n",
       "5435       1597        52  0.032561  0.818542         6113  244.462621   \n",
       "5436       1389        93  0.066955  1.683151         6113  217.634549   \n",
       "5437          0         0       NaN       NaN            0         NaN   \n",
       "\n",
       "       Pct_PWD   Rat_PWD  \n",
       "5013  0.113680  1.123285  \n",
       "5014  0.113680  1.123285  \n",
       "5015  0.113680  1.123285  \n",
       "5016  0.163605  1.616610  \n",
       "5017  0.163605  1.616610  \n",
       "...        ...       ...  \n",
       "5433  0.090196  0.891241  \n",
       "5434  0.130869  1.293133  \n",
       "5435  0.130869  1.293133  \n",
       "5436  0.130869  1.293133  \n",
       "5437       NaN       NaN  \n",
       "\n",
       "[425 rows x 53 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg = results_bg_reordered.copy()\n",
    "bg.loc[bg['County']=='Lake']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14324c8-7407-47e5-846e-f49a8082cceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
